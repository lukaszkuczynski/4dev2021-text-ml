{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02. Text Preprocessing",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3pHayzDwPC_",
        "outputId": "43cd36fa-bc34-4812-d26e-bb612fbc8b4b"
      },
      "source": [
        "zen_of_python = \"\"\"\n",
        "Beautiful is better than ugly.\n",
        "Explicit is better than implicit.\n",
        "Simple is better than complex.\n",
        "Complex is better than complicated.\n",
        "Flat is better than nested.\n",
        "Sparse is better than dense.\n",
        "Readability counts.\n",
        "Special cases aren't special enough to break the rules.\n",
        "Although practicality beats purity.\n",
        "Errors should never pass silently.\n",
        "Unless explicitly silenced.\n",
        "In the face of ambiguity, refuse the temptation to guess.\n",
        "There should be one-- and preferably only one --obvious way to do it.\n",
        "Although that way may not be obvious at first unless you're Dutch.\n",
        "Now is better than never.\n",
        "Although never is often better than *right* now.\n",
        "If the implementation is hard to explain, it's a bad idea.\n",
        "If the implementation is easy to explain, it may be a good idea.\n",
        "Namespaces are one honking great idea -- let's do more of those!\n",
        "\"\"\"\n",
        "\n",
        "sentences = zen_of_python.replace(\"\\n\",\"\").split(\".\")\n",
        "sentences[:5]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Beautiful is better than ugly',\n",
              " 'Explicit is better than implicit',\n",
              " 'Simple is better than complex',\n",
              " 'Complex is better than complicated',\n",
              " 'Flat is better than nested']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1kpZNKA1CRY"
      },
      "source": [
        "sentence = \"Namespaces are one honking great idea -- let's do more of those!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHjLRwr20q8z"
      },
      "source": [
        "# Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75oe1F9g0o3i"
      },
      "source": [
        "from nltk.tokenize import WhitespaceTokenizer, word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCR91_6KvrIl",
        "outputId": "4c04600b-517a-469e-97e4-3fc6eeca5bc4"
      },
      "source": [
        "original_tokens = WhitespaceTokenizer().tokenize(sentence)\n",
        "print(original_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Namespaces', 'are', 'one', 'honking', 'great', 'idea', '--', \"let's\", 'do', 'more', 'of', 'those!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x22g0855_DTD"
      },
      "source": [
        "# Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvOV4HDc_DTG",
        "outputId": "f8917adf-c583-41db-e3eb-e30fdb369b5b"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "english_stopwords = stopwords.words('english')\n",
        "print(english_stopwords[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89gAM1pR_DTM",
        "outputId": "0e6a300c-e0be-48d3-fd62-ab0ecd7750ee"
      },
      "source": [
        "tokens = [token for token in original_tokens if token.lower() not in english_stopwords]\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Namespaces', 'one', 'honking', 'great', 'idea', '--', \"let's\", 'those!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Dr7dUp8C1L"
      },
      "source": [
        "# Clean it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HbwE7vc52t3",
        "outputId": "641ac953-3a3e-40e4-9541-f7a657d1f577"
      },
      "source": [
        "import re\n",
        "\n",
        "regex_looks_like_a_word = r'[a-zA-Z].*'\n",
        "\n",
        "def clean_them(tokens):\n",
        "  clean_tokens = [token for token in tokens if re.match(regex_looks_like_a_word, token)]\n",
        "  return clean_tokens\n",
        "\n",
        "clean_them([\"go\", \"12\", \"--\"])      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['go']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ereumtUA9gbg",
        "outputId": "a60502fa-bdf9-42d8-9d76-7225873c1c4d"
      },
      "source": [
        "cleaned_tokens = clean_them(tokens)\n",
        "cleaned_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Namespaces', 'one', 'honking', 'great', 'idea', \"let's\", 'those!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxqbs8M0541X"
      },
      "source": [
        "# to the Roots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD-yf4xSjdNh"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap6P7ut4xi8e"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw2_k9ev6B26",
        "outputId": "1c83d149-d300-48a4-ddac-fa3b75abac4b"
      },
      "source": [
        "porter = PorterStemmer()\n",
        "[porter.stem(token) for token in cleaned_tokens]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['namespac', 'one', 'honk', 'great', 'idea', \"let'\", 'those!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpdRnEwJ6UMM",
        "outputId": "2bfef314-bd3a-45c5-93e0-626e390555bc"
      },
      "source": [
        "snowball = SnowballStemmer(\"english\")\n",
        "[snowball.stem(token) for token in cleaned_tokens]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['namespac', 'one', 'honk', 'great', 'idea', 'let', 'those!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCFfpvn-98BN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2634f1e1-ad79-449e-c669-3efb33967db6"
      },
      "source": [
        "stemmed_tokens = [snowball.stem(token) for token in cleaned_tokens]\n",
        "stemmed_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['namespac', 'one', 'honk', 'great', 'idea', 'let', 'those!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6unbaUYjfuV"
      },
      "source": [
        "### Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "areL8tJVjk9M"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1TsDD7Vj0IR",
        "outputId": "4d78daf8-c42a-429f-bf39-ccd23bf27958"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA6nhzBGjoQe",
        "outputId": "a308a724-45c3-416b-c25b-653236e4c1e9"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in cleaned_tokens]\n",
        "lemmatized_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Namespaces', 'one', 'honking', 'great', 'idea', \"let's\", 'those!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um9yKUGKkxuc",
        "outputId": "46922d27-365c-4b3f-c909-adc244f5f21b"
      },
      "source": [
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token, pos='n') for token in cleaned_tokens]\n",
        "lemmatized_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Namespaces', 'one', 'honking', 'great', 'idea', \"let's\", 'those!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF-UZcmblOno",
        "outputId": "19c8bbd4-a899-4871-f95e-99e73df640bc"
      },
      "source": [
        "tokens = WhitespaceTokenizer().tokenize('this conference is not like other conferences')\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token.lower(), pos='n') for token in tokens]\n",
        "lemmatized_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'conference', 'is', 'not', 'like', 'other', 'conference']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb2dv8IGmQYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc4a641-8618-4e2a-973c-d472ec1962ca"
      },
      "source": [
        "tokens = WhitespaceTokenizer().tokenize('in nltk you can find lots of corpora')\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token.lower(), pos='n') for token in tokens]\n",
        "lemmatized_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in', 'nltk', 'you', 'can', 'find', 'lot', 'of', 'corpus']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}